{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cca75a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f74bcf",
   "metadata": {},
   "source": [
    "# PyTorch Basic Tensor Manipulation\n",
    "- Vector, Matrix and Tensor\n",
    "- NumPy Review\n",
    "- PyTorch Tensor Allocation\n",
    "- Matrix Multiplication\n",
    "- Other Basic Ops\n",
    "\n",
    "## Vector, Matrix and Tensor\n",
    "### PyTorch Tensor Shape Convention\n",
    "- 2D Tensor (typical simple setting)\n",
    "    - |t| = (batch size, dim)\n",
    "- 3D Tensor (typical computer vision)\n",
    "    - |t| = (batch size, width, height)\n",
    "- 3D Tensor (typical natural language processing)\n",
    "    - |t| = (batch size, length, dim \n",
    "\n",
    "### PyTroch Tensor\n",
    "- pytorch에서 tensor를 만드는 것은 numpy와 동일하다.\n",
    "- torch.FloatTensor()를 이용하면 1차원 2차원 3차원 등 을 많들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9b30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_torch(x):\n",
    "    print(x)\n",
    "    print(f'check type  : {type(x)}')\n",
    "    print(f'check shape : {x.shape}')\n",
    "    print(f'check dim   : {x.dim()}')\n",
    "    print(f'check size  : {x.size()}')\n",
    "    \n",
    "def check_numpy(x):\n",
    "    print(x)\n",
    "    print(f'check type  : {type(x)}')\n",
    "    print(f'check shape : {x.shape}')\n",
    "    print(f'check dim   : {x.ndim}')\n",
    "    print(f'check size  : {x.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8dbf1c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n",
      "check type  : <class 'torch.Tensor'>\n",
      "check shape : torch.Size([7])\n",
      "check dim   : 1\n",
      "check size  : torch.Size([7])\n",
      "\n",
      "[0. 1. 2. 3. 4. 5. 6.]\n",
      "check type  : <class 'numpy.ndarray'>\n",
      "check shape : (7,)\n",
      "check dim   : 1\n",
      "check size  : 7\n"
     ]
    }
   ],
   "source": [
    "one_dim_torch = torch.FloatTensor([0.,1.,2.,3.,4.,5.,6.])\n",
    "check_torch(one_dim_torch)\n",
    "print()\n",
    "one_dim_np = np.array([0.,1.,2.,3.,4.,5.,6.])\n",
    "check_numpy(one_dim_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fa553aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "check type  : <class 'torch.Tensor'>\n",
      "check shape : torch.Size([3, 3])\n",
      "check dim   : 2\n",
      "check size  : torch.Size([3, 3])\n",
      "tensor([[2., 3.],\n",
      "        [5., 6.],\n",
      "        [8., 9.]])\n",
      "torch.Size([3, 2])\n",
      "tensor([4., 5., 6.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "two_dim_torch = torch.FloatTensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "check_torch(two_dim_torch)\n",
    "print(two_dim_torch[:,1:])\n",
    "print(two_dim_torch[:,1:].size())\n",
    "print(two_dim_torch[1,:])\n",
    "print(two_dim_torch[1,:].size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db623bc1",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "#### broadcasting은 자동으로 되기 때문에 주의해야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afad2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.]])\n",
      "check type  : <class 'torch.Tensor'>\n",
      "check shape : torch.Size([1, 2])\n",
      "check dim   : 2\n",
      "check size  : torch.Size([1, 2])\n",
      "\n",
      "[[3 3]]\n",
      "check type  : <class 'numpy.ndarray'>\n",
      "check shape : (1, 2)\n",
      "check dim   : 2\n",
      "check size  : 2\n"
     ]
    }
   ],
   "source": [
    "# Same shape\n",
    "m1 = torch.FloatTensor([[1,2]])  # size = (1,2)\n",
    "m2 = torch.FloatTensor([[2,1]])  # size = (1,2)\n",
    "same_shape = m1+m2\n",
    "check_torch(same_shape)\n",
    "print()\n",
    "# numpy\n",
    "m3 = np.array([[1,2]])\n",
    "m4 = np.array([[2,1]])\n",
    "np_same_shape = m3+m4\n",
    "check_numpy(np_same_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8945a0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.]])\n",
      "check type  : <class 'torch.Tensor'>\n",
      "check shape : torch.Size([1, 2])\n",
      "check dim   : 2\n",
      "check size  : torch.Size([1, 2])\n",
      "\n",
      "[[3 4]]\n",
      "check type  : <class 'numpy.ndarray'>\n",
      "check shape : (1, 2)\n",
      "check dim   : 2\n",
      "check size  : 2\n"
     ]
    }
   ],
   "source": [
    "# Vector + Scala\n",
    "m1 = torch.FloatTensor([[1,2]])  # size = (1,2)\n",
    "m2 = torch.FloatTensor([2])  # size = (1,)\n",
    "same_shape = m1+m2  # m2 => [[2,2]]\n",
    "check_torch(same_shape)\n",
    "print()\n",
    "# numpy\n",
    "m3 = np.array([[1,2]])\n",
    "m4 = np.array([2])\n",
    "np_same_shape = m3+m4\n",
    "check_numpy(np_same_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e04cf12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.],\n",
      "        [4.]])\n",
      "check type  : <class 'torch.Tensor'>\n",
      "check shape : torch.Size([2, 1])\n",
      "check dim   : 2\n",
      "check size  : torch.Size([2, 1])\n",
      "\n",
      "[[3]\n",
      " [4]]\n",
      "check type  : <class 'numpy.ndarray'>\n",
      "check shape : (2, 1)\n",
      "check dim   : 2\n",
      "check size  : 2\n"
     ]
    }
   ],
   "source": [
    "# Matrix + Scalar\n",
    "m1 = torch.FloatTensor([[1],[2]])  # size = (2,1)\n",
    "m2 = torch.FloatTensor([2])  # size = (1,2)\n",
    "same_shape = m1+m2\n",
    "check_torch(same_shape)\n",
    "print()\n",
    "# numpy\n",
    "m3 = np.array([[1],[2]])\n",
    "m4 = np.array([2])\n",
    "np_same_shape = m3+m4\n",
    "check_numpy(np_same_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82f2b9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [2., 3.]])\n",
      "check type  : <class 'torch.Tensor'>\n",
      "check shape : torch.Size([2, 2])\n",
      "check dim   : 2\n",
      "check size  : torch.Size([2, 2])\n",
      "\n",
      "[[3 4]\n",
      " [2 3]]\n",
      "check type  : <class 'numpy.ndarray'>\n",
      "check shape : (2, 2)\n",
      "check dim   : 2\n",
      "check size  : 4\n"
     ]
    }
   ],
   "source": [
    "# different shape matrix\n",
    "m1 = torch.FloatTensor([[1,2]])  # size = (1,2)\n",
    "m2 = torch.FloatTensor([[2],[1]])  # size = (2,1)\n",
    "same_shape = m1+m2\n",
    "check_torch(same_shape)\n",
    "print()\n",
    "# numpy\n",
    "m3 = np.array([[1,2]])\n",
    "m4 = np.array([[2],[1]])\n",
    "np_same_shape = m3+m4\n",
    "check_numpy(np_same_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f1ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Mul vs Matmul\n",
      "-------------\n",
      "Matmul\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "check type  : <class 'torch.Tensor'>\n",
      "check shape : torch.Size([2, 2])\n",
      "check dim   : 2\n",
      "check size  : torch.Size([2, 2])\n",
      "tensor([[1.],\n",
      "        [2.]])\n",
      "check type  : <class 'torch.Tensor'>\n",
      "check shape : torch.Size([2, 1])\n",
      "check dim   : 2\n",
      "check size  : torch.Size([2, 1])\n",
      "matmul : tensor([[ 5.],\n",
      "        [11.]])\n",
      "Mul\n",
      "Mul : tensor([[1., 2.],\n",
      "        [6., 8.]]), \n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print('-------------')\n",
    "print('Mul vs Matmul')\n",
    "print('-------------')\n",
    "print('Matmul')\n",
    "m1 = torch.FloatTensor([[1,2],[3,4]])  # (2, 2)\n",
    "m2 = torch.FloatTensor([[1],[2]])  # (2,1)\n",
    "check_torch(m1)\n",
    "check_torch(m2)\n",
    "print(f'matmul : {m1.matmul(m2)}')  # (2,1) (2,2) * (2,1)의 행렬곱이 진행되어 2,1의 값이 나온다\n",
    "print(\"Mul\")\n",
    "print(f'Mul : {m1*m2}, \\n{m1.mul(m2)}')  # (2,1) (2,2) * (2,1)의 행렬곱이 진행되어 2,1의 값이 나온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5764644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([1,2])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93aeec0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long\n",
      "\n",
      "텐서에는 자료형이라는 것이 있습니다. 각 데이터형별로 정의되어져 있는데, \n",
      "예를 들어 32비트의 부동 소수점은 torch.FloatTensor를, 64비트의 부호 있는 정수는 torch.LongTensor를 사용합니다. \n",
      "GPU 연산을 위한 자료형도 있습니다. \n",
      "예를 들어 torch.cuda.FloatTensor가 그 예입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Can't use mean() on integers\n",
    "t_lt = torch.LongTensor([1,2])  # LongTensor가 정수형 64비트의 자료형이기 때문에 소수점이 나올 수 없다.\n",
    "try:\n",
    "    print(t_lt.mean())\n",
    "except Exception as exc:\n",
    "    print(exc)\n",
    "print('''\n",
    "텐서에는 자료형이라는 것이 있습니다. 각 데이터형별로 정의되어져 있는데, \n",
    "예를 들어 32비트의 부동 소수점은 torch.FloatTensor를, 64비트의 부호 있는 정수는 torch.LongTensor를 사용합니다. \n",
    "GPU 연산을 위한 자료형도 있습니다. \n",
    "예를 들어 torch.cuda.FloatTensor가 그 예입니다.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d94120f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "t_matrix = torch.LongTensor([[1,2],[3,4]]).float()\n",
    "print(t_matrix.mean())\n",
    "print(t_matrix.mean(dim=0)) # dim=0 인 것은 0번째 차원을 없앤고 출력 해봐라는 것. np의 axis와 같은 개념\n",
    "# (2,2) => (1,2) or (2,)\n",
    "print(t_matrix.mean(dim=1))\n",
    "# (2,2) => (2,1)\n",
    "print(t_matrix.mean(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c56e15fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "check type  : <class 'numpy.ndarray'>\n",
      "check shape : (2, 2)\n",
      "check dim   : 2\n",
      "check size  : 4\n",
      "2.5\n",
      "[4 6] [2. 3.]\n",
      "[4 6]\n",
      "check type  : <class 'numpy.ndarray'>\n",
      "check shape : (2,)\n",
      "check dim   : 1\n",
      "check size  : 2\n",
      "[3 7] [1.5 3.5]\n",
      "[3 7] [1.5 3.5]\n"
     ]
    }
   ],
   "source": [
    "s = np.array([[1,2],[3,4]])\n",
    "check_numpy(s)\n",
    "print(s.mean())\n",
    "print(s.sum(axis=0), s.mean(axis=0))\n",
    "check_numpy(s.sum(axis=0))\n",
    "print(s.sum(axis=1), s.mean(axis=1))\n",
    "print(s.sum(axis=-1), s.mean(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87679e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
